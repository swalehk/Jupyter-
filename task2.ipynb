# Importing necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split

# Sample dataset (replace with real-world data)
data = {
    'age': [34, 45, 23, 39, 51],
    'education': ['College', 'Graduate', 'High School', 'College', 'Graduate'],
    'income': [50000, 70000, 30000, 45000, 80000],
    'previous_voter': ['Yes', 'Yes', 'No', 'No', 'Yes'],
    'region': ['Urban', 'Suburban', 'Rural', 'Urban', 'Urban'],
    'social_media_activity': ['High', 'Low', 'Medium', 'High', 'High'],
    'voted': [1, 1, 0, 1, 1]
}

# Creating a DataFrame
df = pd.DataFrame(data)

# Display the DataFrame
print("Initial DataFrame:")
print(df)

# Basic Data Exploration
# 1. Display the summary statistics
print("\nSummary Statistics:")
print(df.describe())

# 2. Plot distributions of age and income
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.hist(df['age'], bins=5, color='skyblue', edgecolor='black')
plt.title('Age Distribution')
plt.xlabel('Age')
plt.ylabel('Frequency')

plt.subplot(1, 2, 2)
plt.hist(df['income'], bins=5, color='lightgreen', edgecolor='black')
plt.title('Income Distribution')
plt.xlabel('Income')
plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

# 3. Countplot of categorical features
plt.figure(figsize=(10, 5))

plt.subplot(1, 3, 1)
sns.countplot(data=df, x='education', palette='Set2')
plt.title('Education Level Distribution')

plt.subplot(1, 3, 2)
sns.countplot(data=df, x='region', palette='Set2')
plt.title('Region Distribution')

plt.subplot(1, 3, 3)
sns.countplot(data=df, x='social_media_activity', palette='Set2')
plt.title('Social Media Activity Distribution')

plt.tight_layout()
plt.show()

# 4. Correlation Heatmap for numerical columns
corr = df[['age', 'income']].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

# Data Preprocessing
# 1. Handle missing values (for this example, no missing data, but in real data, you'd handle it)
# For missing numerical data: df['column'].fillna(df['column'].mean(), inplace=True)

# 2. Encoding categorical data
# Label Encoding for binary columns
le = LabelEncoder()
df['previous_voter'] = le.fit_transform(df['previous_voter'])

# One-Hot Encoding for columns with more than two categories
df = pd.get_dummies(df, columns=['education', 'region', 'social_media_activity'], drop_first=True)

print("\nData after Encoding:")
print(df)

# 3. Feature Scaling
scaler = StandardScaler()
df[['age', 'income']] = scaler.fit_transform(df[['age', 'income']])

print("\nData after Scaling:")
print(df)

# 4. Splitting Data into Features (X) and Target (y)
X = df.drop('voted', axis=1)  # Features
y = df['voted']  # Target variable

# 5. Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("\nTraining and Testing Split:")
print(f"Training Features Shape: {X_train.shape}, Testing Features Shape: {X_test.shape}")
print(f"Training Target Shape: {y_train.shape}, Testing Target Shape: {y_test.shape}")
